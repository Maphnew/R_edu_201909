#---------------------------------------------------------------------------
# 1. 일표본 t-검정(one sample t-test)

## 개념
# - 단일모집단에서 관심이 있는 연속형 변수의 평균값을 
#   특정 기준값과 비교하고자 할 때 사용하는 검정방법


## 함수
# - t.test( x, alternative=c(“two.sided”, “less”, “greater”), mu=0 )
# - x : 표본으로부터 관측한 값(수치형 벡터)
# - alternative : 양측검정시 “two.sided”, 단측검정시 “less”, “greater” 입력
# - mu : 검정 시 기준이 되는 값

#--------------------------------------------------------------------------

# 예제 : A 과수원에서 생산된 사과의 평균무게는 200g으로 알려져 있다. 
# 실제로도 그러한지 알아보기 위해 A 과수원에서 생산되는 사과 15개를 임의로 뽑아서 무게를 측정하였다. 
# 해당 데이터를 가지고 A 과수원에서 생산되는 전체 사과 무게의 평균이 
# 사과들의 평균 무게가 200g과 같다고 할 수 있는지 검정해보자. (양측검정 수행, 유의수준 = 0.05)
# 귀무가설 : A과수원에서 생산되는 사과무게의 평균값은 200g이다.
# 대립가설 : A과수원에서 생산되는 사과무게의 평균값은 200g이 아니다.

# 데이터 입력 : 15개의 관측값을 data라는 변수에 입력
data<-c(200, 210, 180, 190, 185, 170, 180, 180, 210, 180, 183, 191, 204, 201, 186) 


# 정규성 검정 (샤피로-윌크 검정)
options(digits=7)
shapiro.test(data)
# 귀무가설 : 모집단은 정규분포를 따른다.
# 대립가설 : 모집단은 정규분포를 따르지 않는다.
# 유의확률(p-value)는 0.20497로 귀무가설을 채택한다.
# 즉, A 과수원에서 생산되는 사과의 무게는 정규분포를 따른다고 할 수 있다.

# 일표본 t-검정 수행
t.test(data, alternative="two.sided", mu=200, conf.level=0.95)
#- conf.level : 95%에서의 신뢰구간

# 일표본 t-검정 수행 결과, 검정통계량(t값)은 -3.1563, df(자유도)는 14, 
# 유의확률(p-value)은 0.007004이다. 
# p-value가 유의수준 0.05보다 작기 때문에 귀무가설을 기각하고,
# ‘A 과수원에서 생산되는 사과의 평균무게는 200g이 아니다.’ 라는 결론을 내릴 수 있다.



#ex) 2010년도에 서울 지역의 고등학교 1학년 남학생의 몸무게를 전수 조사하였더니 평균이 63.0 kg, 표준편차가 8.0 kg이 나왔다.  
#   2015년에 15명의 남학생을 무작위로 표본을 추출하여 몸무게를 재어보니 
#   {70.2, 54.9, 67.0, 60.5, 63.4, 61.9, 71.8, 66.1, 72.6, 73.0, 68.7, 70.3, 66.2, 55.6, 65.9} 와 같이 나왔을 때 
#   서울 지역 고등학교 1학년 남학생의 몸무게가 5년 전보다 더욱 증가했다고 볼 수 있는가?

# Q-1. 귀무가설과 대립가설을 쓰시오.

#solution

#귀무가설 :  서울지역 고딩 1학년 남학생의 몸무게가 5년 전보다 증가하지 않음.
# H0: m=63
#대립가설 :  서울지역 고딩 1학년 남학생의 몸무게가 5년 전보다 증가.
# H1: m>63 => 단측검정

# Q-2. 서울 지역 고등학교 1학년 남학생의 몸무게가 5년 전보다 더욱 증가하였다는 대립가설을 검정하시오.
#      (정규성 검정을 진행하고 유의수준 0.05에서 검정하시오.)
#solution

x <- c(70.2, 54.9, 67.0, 60.5, 63.4, 61.9, 71.8, 66.1, 72.6, 73.0, 68.7, 70.3, 66.2, 55.6, 65.9)
shapiro.test(x)
# W = 0.92644, p-value = 0.2413
# 유의확률(p-value)는 0.2413으로 귀무가설을 채택한다.

t.test(x, alternative="greater", mu=63.0, conf.level=0.95)
# 일표본 t-검정 수행 결과, 검정통계량(t값)은 1.9507,df(자유도)는 14,
# 유의확률(p-value)은 0.0357이다.
# p-value가 유의수준 0.05보다 작기 때문에 귀무가설을 기각한다.
# ‘서울지역 고딩 1학년 남학생의 몸무게가 5년 전보다 증가.’ 라는 결론을 내릴 수 있다.

# 귀무가설 :  
# 대립가설 :  
# 유의확률(p-value)는  

 
# 일표본 t-검정 수행 결과, 검정통계량(t값)은        , df(자유도)는    , 
# 유의확률(p-value)은        이다. 
# p-value가 유의수준 0.05보다      때문에        을 기각한다.


#---------------------------------------------------------------------------
# 2. 대응표본 t-검정(paired sample t-test)

## 개념
# - 단일모집단에 대해 두 번의 처리를 가했을 때, 두 개의 처리에 따른 
#   평균의 차이를 비교하고자 할 때 사용하는 검정방법


## 함수
# t.test( x, y, alternative=c(“two.sided”, “less”, “greater”), paired=TRUE, m=0 )
# x : 처리방법이 x일 때의 관측값 (수치형 벡터)
# y : 처리방법이 y일 때의 관측값 (수치형 벡터)
# alternative : 양측검정시 “two.sided”, 단측검정시 “less”, “greater” 입력
# paired : 대응표본 t-검정을 수행할지에 대한 여부 (인자값을 TRUE로 지정해야 한다.)
# m : 검정의 기준이 되는 값으로 기본 값은 0이다.
#    (대응표본 t-검정에서는 모평균의 차이가 0인지를 검정하기 때문에, m 인자는 적지 않아도 된다.)

#---------------------------------------------------------------------------

# 예제 : 10명의 환자를 대상으로 수면영양제를 복용하기 전과 후의 수면시간을 측정하여 
# 영양제의 효과가 있는지를 판단하고자 한다. 
# 영양제 복용 전과 후의 평균 수면시간에 차이가 있는지를 알아보는데, 
# 단측검정을 수행하여 영양제 복용 후에 수면시간이 더 늘어났는지를 검정해보자. 
# (표본이 정규성을 만족한다는 가정 하에 단측검정 수행, 유의수준 = 0.05)
# 귀무가설 : 수면영양제를 복용하기 전과 후의 평균 수면시간에는 차이가 없다. (D=0)
# 대립가설 : 수면영양제를 복용하기 전과 후의 평균 수면시간 차이는 0보다 작다.(D<0)

# 데이터 입력 : 10명의 환자에 대해서 영양제를 복용하기 전(before)과 후(after)의 수면시간을 data라는 변수에 입력
data <- data.frame(before = c(7, 3, 4, 5, 2, 1, 6, 6, 5, 4),
                   after = c(8, 4, 5, 6, 2, 3, 6, 8, 6, 5))

# 대응표본 t-검정 수행
t.test(data$before, data$after, alternative="less", paired = TRUE)

# 수면영양제를 복용하기 전과 후의 평균 수면시간 차이가
# 비교하고자 하는 값(0)보다 작은지에 대하여 검정을 수행하기 때문에 
# alternative 인자에는 “less”를 입력한다.


# 대응표본 t-검정 수행 결과, 검정통계량(t값)은 -4.7434, df(자유도)는 9, 
# 유의확률(p-value)은 0.0005269다. 
# p-value가 유의수준 0.05보다 작기 때문에 귀무가설을 기각하고, 
# ‘수면영양제를 복용하기 전과 후의 평균 수면시간의 차이는 통계적으로 유의하며, 
# 영양제를 복용하기 전과 후의 수면시간 차이는 0보다 작다.
# 따라서 수면 영양제를 복용한 후 수면시간이 늘었다.’ 라는 결론을 내릴 수 있다.

#ex) 어느 제약회사가 개발 중인 약은 3개월 동안 이 약을 먹으며 고지한 생활규칙을 지키면 2kg 이상의 효과를 볼 수 있다고 자신합니다.
#    출시 전 다이어트 약의 효과를 측정하고 싶어 참가자 10명을 모집하여, 
#    이 회사는 참가자들에게 3개월치 약을 주었고 현재 몸무게와 3개월 뒤 몸무게를 비교하려 합니다.
#    복용 전과 복용 후의 몸무게는 아래와 같다.

# 복용 전 - {   74, 75, 75, 76, 76, 78, 78, 79, 81, 82}
# 복용 후 - {70, 71, 73, 73, 75, 76, 76, 77, 78, 80}

#    현재 몸무게와 3개월 뒤 몸무게의 평균값은 같은지 검정해보시오.


# Q-1. 귀무가설과 대립가설을 쓰시오.

#solution

#귀무가설 : 고지된 생활규칙을 지키면서 3개월치 약을 복용하면 2kg이상의 다이어트 효과를 볼 수 없다, 몸무게는 줄어들지 않는다.
#대립가설 : 고지된 생활규칙을 지키면서 3개월치 약을 복용하면 2kg이상의 다이어트 효과를 볼 수 있다.


# Q-2. 다이어트 약의 복용 전과 복용 후의 몸무게의 평균이 다른지에 대해 가설검정하시오.
#      (유의수준 0.05에서 검정하시오.)
#solution

x0<-c(74, 75, 75, 76, 76, 78, 78, 79, 81, 82)
x1<-c(70, 71, 73, 73, 75, 76, 76, 77, 78, 80)
data <- data.frame(before = x0, after = x1)
t.test(data$before, data$after, alternative="less", paired = TRUE)
t.test(data$before, data$after, alternative="greater", paired = TRUE)
t.test(data$before, data$after, alternative="two.sided", paired = TRUE)


# 대응표본 t-검정 수행 결과, 검정통계량(t값)은        , df(자유도)는    , 
# 유의확률(p-value)은        이다. 
# p-value가 유의수준 0.05보다      때문에        을 기각한다.

#---------------------------------------------------------------------------
# 3. 독립표본 t-검정(paired sample t-test)

## 개념
# - 두 개의 독립된 모집단의 평균을 비교하고자 할 때 사용하는 검정방법


## 함수
# 1) 등분산 검정
# var.test( formula, data, alternative )
# x : 모집단1로부터 측정한 관측값 (수치형 벡터)
# y : 모집단2로부터 측정한 관측값 (수치형 벡터)
# formula : 수치형 벡터(종속변수)~집단분류(독립변수)
#           데이터프레임을 var.test함수에 적용시킬 때 사용
# data : 등분산 검정을 수행할 데이터명
# alternative : 양측검정시 “two.sided”, 단측검정시 “less”, “greater” 입력


# 2) 독립표본 t-검정
# t.test( x, y, alternative, var.equal=FALSE )
# t.test( formula, data, alternative, var.equal=FALSE )

# x : 모집단1로부터 측정한 관측값 (수치형 벡터)
# y : 모집단2로부터 측정한 관측값 (수치형 벡터)
# formula : 수치형 벡터(종속변수)~집단분류(독립변수)
#           데이터프레임을 t.test함수에 적용시킬 때 사용
# data : t-검정을 수행할 데이터명
# alternative : 양측검정시 “two.sided”, 단측검정시 “less”, “greater” 입력
# equal : 등분산성을 만족하는지의 여부 (TRUE 혹은 FALSE로 입력)

# 만약 등분산성이 만족하지 않으면 Wilcoxon's rank sum test 
# 또는 Welch's t-test(equal=F) 실시해야함.

#---------------------------------------------------------------------------

# 예제 : A, B 두 지역의 겨울 낮 최고기온에 차이가 있는지를 알아보기 위해 
# 약 10일 동안 두 지역의 낮 최고기온을 측정한 데이터로 독립표본 t-검정을 수행해보자.
# (표본이 정규성을 만족한다는 가정 하에 단측검정 수행, 유의수준 = 0.05)
# 귀무가설 : A, B 두 지역에 따른 겨울 낮 최고기온은 차이가 없다. 
# 대립가설 : A, B 두 지역에 따른 겨울 낮 최고기온은 차이가 있다. 


# 데이터 입력 : A, B지역에 대한 10일 동안의 겨울 낮 최고기온 데이터와 
# 지역구분 데이터를 이용해 weather라는 데이터프레임을 생성
group<-factor(rep(c("A","B"),each=10))  #집단구분을 위한 변수
A<-c(-1, 0, 3, 4, 1, 3, 3, 1, 1, 3)     #A 지역의 온도
B<-c(6, 6, 8, 8, 11, 11, 10, 8, 8, 9)   #B 지역의 온도
weather<-data.frame(group=group, temp=c(A,B)) #데이터프레임 생성

# 등분산 검정 수행
var.test(temp~group, data=weather, alternative="two.sided") 

# 등분산 검정의 결과 유의확률(p-value)이 0.7833으로 
# 유의수준 0.05보다 크기 때문에 귀무가설을 기각하지 않는다. 
# 따라서 A, B 두 집단의 데이터는 등분산 가정을 만족한다고 볼 수 있다.
# => 두 모집단이 등분산성을 만족한다는 가정 하에 
# t.test함수를 이용해 독립표본 t-검정을 수행해보자. 


# 독립표본 t-검정을 수행
t.test(temp~group, data=weather, alternative="two.sided", var.equal=TRUE)

# 독립표본 t-검정 수행 결과, 검정통계량(t값)은 -8.806, df(자유도)는 18, 유의확률(p-value)은 6.085e-08다. 
# p-value가 0에 가까운 매우 작은 숫자로 유의수준 0.05보다 작기 때문에 귀무가설을 기각한다. 
# 따라서 ‘A, B 두 지역의 겨울 낮 최고기온에는 통계적으로 유의한 차이가 존재한다.’ 라는 결론을 내릴 수 있다.

#ex) 어느 회사 간부가 사내 두 가지 부서의 직무 만족도의 차이를 알고 싶어 합니다.
#    A 부서에서 12명, B 부서에 10명의 표본 참가자를 랜덤 추출하여 
#    검증된 설문지를 이용하여 직무 만족도도(1~10점)를 조사하였습니다.
#    각 부서의 설문지 점수들은 아래와 같습니다.

# A 부서(12명) - {8.2, 8.3, 8.4, 9.3, 8.3, 7.0, 7.8, 7.9, 7.5, 9.5, 6.0, 7.6}
# B 부서(10명) - {8.2, 7.0, 6.5, 8.2, 6.4, 8.2, 6.7, 7.6, 5.3, 6.8}

#    회사 간부는 두 부서 간의 직무 만족도 평균이 차이가 있을 것이라 생각합니다.
#    두 부서의 직무 만족도 평균이 다른지에 대해 검정해보시오.


# Q-1. 귀무가설과 대립가설을 쓰시오.

#solution

#귀무가설 :  두 부서 간의 직무 만족도 모평균이 차이가 없다.
#대립가설 :  두 부서 간의 직무 만족도 모평균이 차이가 있다.


# Q-2. 두 부서의 직문 만족도 평균이 다른지에 대해 가설검정하시오.
#      (유의수준 0.05에서 검정하시오.)
#solution

A <- c(8.2, 8.3, 8.4, 9.3, 8.3, 7.0, 7.8, 7.9, 7.5, 9.5, 6.0, 7.6)
B <- c(8.2, 7.0, 6.5, 8.2, 6.4, 8.2, 6.7, 7.6, 5.3, 6.8)

var.test(A,B, alternative="two.sided") 
# 등분산 검정의 결과 유의확률(p-value)이 0.9482 으로 
# 유의수준 0.05보다 크기 때문에 귀무가설을 기각하지 않는다. 
# 따라서 A, B 두 집단의 데이터는 등분산 가정을 만족한다고 볼 수 있다.

t.test(A,B,var.equal = T,conf.level = 0.95,alternative = "two.sided")
# 독립표본 t-검정 수행 결과, 검정통계량(t값)은  2.1989  , df(자유도)는  20, 
# 유의확률(p-value)은  0.03982이다. 
# p-value가 유의수준 0.05보다  작기 때문에  귀무가설을 기각한다.
# 따라서 `두 부서의 직무 만족도 평균이 통계적으로 유의한 차이가 존재한다.`라고 할 수 있다.

########## 4. 교차분석

#----------------------------------------------------------------------------------------
# 4.1 적합도 검정
# 개념 : 실험에서 얻어진 관측값들이 예상한 이론과 일치하는지 아닌지를 검정하는 

# 귀무가설 : 실제 분포와 이론적 분포 간에는 차이가 없다. (두 분포가 일치한다)
# 대립가설 : 실제 분포와 이론적 분포 간에는 차이가 있다. (두 분포가 일치하지 않는다)
#----------------------------------------------------------------------------------------
# 예제 : MASS 패키지의 survey 데이터에서 W.Hnd 변수는 설문 응답자가 
# 왼손잡이(Left) 인지 오른손잡이(Right) 인지를 나타낸다. 
# R을 이용하여 W.Hnd 변수에 대한 분할표를 생성하고, 아래와 같은 가설에 대한 적합도 검정을 수행해보자.

# 귀무가설 : 전체 응답자 중 왼손잡이는 20%, 오른손잡이는 80%이다.
# 대립가설 : 전체 응답자 중 왼손잡이의 비율이 20%, 오른손잡이의 비율이 80%라고 할 수 없다.


# 데이터 불러오기
data(survey, package="MASS")  # MASS 패키지의 survey 데이터 불러오기
str(survey)                   # survey 데이터의 구조 확인

# W.Hnd변수의 분할표 확인
table(survey$W.Hnd)  

# 적합도 검정 수행
data_1<-table(survey$W.Hnd)  #W.Hnd변수의 분할표를 data변수에 저장 
chisq.test(data_1, p=c(0.2,0.8))
##-- 검정 결과, 유의확률(p-value)이 2.015e-06로 0.05보다 작으므로 
##   ‘전체 응답자 중 왼손잡이는 20%, 오른손잡이는 80%이다.’라는 귀무가설을 기각한다.



#----------------------------------------------------------------------------------------
# 4.2 독립성 검정
# 개념 : 모집단이 두 개의 변수 A, B에 의해 범주화되었을 때, 
#        이 두 변수들 사이의 관계가 독립인지 아닌지를 검정하는 것

# 귀무가설 : 두 변수 사이에는 연관이 없다. (독립이다)
# 대립가설 : 두 변수 사이에는 연관이 있다. (종속이다)
#----------------------------------------------------------------------------------------
# 예제 : MASS 패키지의 survey 데이터에서 W.Hnd 변수는 설문 응답자가 
# 왼손잡이(Left) 인지 오른손잡이(Right) 인지를 나타낸다. 
# R을 이용하여 W.Hnd 변수에 대한 분할표를 생성하고, 아래와 같은 가설에 대한 독립성 검정을 수행해보자.

# 귀무가설 : 성별(Sex)과 운동량(Exer) 변수는 서로 독립이다.
# 대립가설 : 성별(Sex)과 운동량(Exer) 변수는 서로 독립이 아니다.

# 데이터 불러오기
data(survey, package="MASS")  # MASS 패키지의 survey 데이터 불러오기
str(survey)                   # survey 데이터의 구조 확인


# 4.2.1 카이제곱 검정
# 독립성 검정을 위해서는 Sex와 Exer라는 두 개의 변수만 사용하기 때문에 xtabs()라는 함수의 사용이 필요하다.
# xtabs() : 지정된 변수들로 표를 만들어주는 함수

# xtabs함수를 이용해 분할표 생성
xtabs(~Sex+Exer,data=survey)

# 카이제곱 검정 수행
chisq.test(xtabs(~Sex+Exer,data=survey))
##-- 검정 결과, 유의확률(p-value)이 0.05731로 0.05보다 크기때문에 귀무가설을 기각하지 않는다.
##   즉, 성별과 운동량은 독립이다.


# 4.2.2 카이제곱 검정
# 표본의 수가 적을 때에 카이제곱 검정 결과는 부정확할 수 있음
# → 이 때 많이 사용하는 것이 피셔의 정확검정


# 피셔의 정확 검정 수행
fisher.test(xtabs(~Sex+Exer,data=survey))
##-- 검정 결과, 유의확률(p-value)이 0.05556로 0.05보다 크기때문에 귀무가설을 기각하지 않는다.
##   즉, 성별과 운동량은 독립이다.



#----------------------------------------------------------------------------------------
# 4.3 동질성 검정
# 개념 : 모집단이 임의의 변수에 따라 R개의 속성으로 범주화되었을 때, 
#         R개의 부분 모집단에서 추출한 각 표본인 C개의 범주화된 집단의 분포는 
#        서로 동일한지 아닌지를 검정하는 것을 의미한다.
# 동질성 검정에는 카이제곱 통계량이 사용된다.

# 귀무가설(H0) : p1j = p2j = ... = prj,  (j = 1, ..., c)
# 대립가설(H1) : H0가 아니다
#----------------------------------------------------------------------------------------
# 예제 : 초등학교 1학년 남학생 100명과 여학생 200명을 무작위로 추출하여 
# '뽀로로', '짱구는 못말려', '로봇카 폴리' 의 세 가지 TV 프로그램 중 
# 가장 선호하는 프로그램은 어떤 것인지를 조사하였다. 
# 유의수준 0.05 하에서 남학생이 선호하는 TV 프로그램과 여학생이 선호하는 TV프로그램이 
# 동일한지 검정하여라.    


# 데이터 입력
raw_data <- c(50, 30, 20, 50, 80, 70) 
data_matrix <- matrix(raw_data, byrow=TRUE, nrow=2) 

# 행이름, 열이름 부여
dimnames(data_matrix) <- list("Gender" = c("Boys", "Girls"), "TV_Preferences" = c("Pororo", "JJangGu", "RobotCar")) 

# 동질성 검정을 하기위해 행과 열의 합을 구한 표를 산출 : addmargins() 이용
addmargins(data_matrix) 
prop.table(data_matrix) 

# 동질성 검정 수행 : chisq.test() 이용
chisq.test_output <- chisq.test(data_matrix) 

chisq.test_output            # 동질성 검정 결과
chisq.test_output$observed   # 관측도수
chisq.test_output$expected   # 기대도수
chisq.test_output$statistic  # 카이제곱 통계량
chisq.test_output$parameter  # 자유도=2=(행의 수-1)*(열의 수-1)
chisq.test_output$p.value    # 동질성 검정에 대한 유의확률

##-- 카이제곱 통계량 값은 19.318이고, P-value가 6.384e-05 로서 
##  유의수준 α 0.05 보다 매우 작기 때문에 귀무가설을 기각한다.
#   따라서 "남학생과 여학생별 선호하는 TV프로그램은 동일하지 않다"고 판단할 수 있다.



##### 1. 연습문제
# 한 냉장고 회사는 가족규모에 따라 구매하는 냉장고의 크기가 다른지를 알아보고자
# 가족규모와 보유하고 있는 냉장고의 크기를 묻는 설문을 실시하였다.
# 설문결과는 fam_fridge.csv 데이터에 저장되어 있으며,
# 해당 데이터를 이용하여 가족규모와 냉장고 크기 사이에 연관성이 있는지 검정하여라.


##### Solution
# 데이터 불러오기
setwd("d:/R_edu_201909")
getwd()

famfri <- read.csv("fam_fridge.csv", header=T)
str(famfri)

# 가설 설정
# 귀무가설 : 가족규모와 보유하고 있는 냉장고의 크기는 독립이다.
# 대립가설 : 가족규모와 보유하고 있는 냉장고의 크기는 독립이 아니다.


# 분할표 생성
xtabs(~family_size+fridge_size,data=famfri)
# 검정 수행
chisq.test(xtabs())

# 검정 결과, 
# 
# 

#---------------------------------------------------------------------------
# 5. 일원배치 분산분석

## 개념
# - 반응값에 대해 하나의 범주형 변수의 영향을 알아보기 위해 사용되는 검증 방법
#   (F 검정 통계량을 이용)

# - 가정 : 분산분석은 정규성과 등분산성의 가정을 따라야함.
#   정규성을 따르지 않는다면 Kruskal-Wallis 검정을 실시해야하며, 등분산성이 만족하지 않으면 Welch's ANOVA 수행
#   정규성과 등분산성의 가설검정의 귀무, 대립가설은 아래와 같음
#   귀무가설 : 모집단은 정규분포(등분산성)을 따른다.
#   대립가설 : 모집단은 정규분포(등분산성)을 따르지 않는다.

# - 사후 검정 : 분산분석의 결과 귀무가설이 기각되어 
#   적어도 한 집단에서 평균의 차이가 있음이 통계적으로 증명되었을 경우, 
#   어떤 집단들에 대해서 평균의 차이가 존재하는지를 알아보기 위해 실시하는 분석
#   방법은 Tukey, Dunnett, Duncan, Fisher’s LSD, Bonferroni, Scheffe, Dunnett T3 등이 있음.
#   귀무가설 : 집단들 사이의 평균은 같다
#   대립가설 : 집단들 사이의 평균은 같지 않다


## 함수
# 1) 분산분석
# aov(formula, data)
# formula : 반응변수~그룹변수
# data : 분석하고자 하는 데이터명


# 2) 정규성 & 등분산성 가정
# shapiro.test(data) - 정규성 검정
# bartlett.test(formula, data)
# formula : 반응변수~그룹변수
# data : 분석하고자 하는 데이터명


# 3) 사후검정
# TukeyHSD(x, conf.level = 0.95, ...)
# x : 분산분석의 결과
# conf.level : 신뢰수준에 해당하며, 기본값은 0.95임

# scheffe.test(x, trt, alpha, console)
# x : 분산분석의 결과
# trt : 분산분석의 집단들을 의미
# alpha : 유의수준
# console : 출력여부를 물음

#---------------------------------------------------------------------------

# 예제 : R에 내장되어 있는 iris 데이터를 이용하여 종(Species)별로 
# 꽃받침의 폭(Sepal.Width)의 평균이 같은지 혹은 차이가 있는지를 확인하기 위해 일원배치 분산분석을 수행해보자.
# 귀무가설 : 세 가지 종에 대해 Sepal.Width의 평균은 모두 같다.
# 대립가설 : 적어도 하나의 종에 대한 Sepal.Width의 평균값에는 차이가 있다. 

# R에서 분산분석을 수행할 때 주의해야할 점은 
# 그룹을 구분하는 기준이 되는 변수(ex. 본 예제의 Species 변수)는 반드시 factor형이어야 한다.

str(iris)   #iris 데이터의 구조 확인

#정규성 및 등분산성 확인
shapiro.test(iris$Sepal.Width)
# p-value가 0.1012로 유의수준 0.05하에서 귀무가설을 채택하여 정규성을 만족한다.

bartlett.test(Sepal.Width~Species, data=iris)
# p-value가 0.3515로 유의수준 0.05하에서 귀무가설을 채택하여 등분산성을 만족한다.

# 분산분석 수행
result<-aov(Sepal.Width~Species, data=iris) #분산분석 결과를 result 변수에 저장
summary(result)                             #분산분석표 확인

# 분산분석표를 통해 확인한 결과, SSA의 자유도는 2(집단의 수-1=3-1), 
# SST의 자유도는 147(관측값의 수-집단의 수=150-3)임을 확인할 수 있다.

# 분석 결과, p-value 값(<2e-16)이 매우 작게 나와 유의수준 0.05 하에서 귀무가설을 기각한다. 
# 따라서 세가지 종(Species)에 따른 꽃받침 폭(Sepal.Width)이 모두 동일하지는 않다고 결론내릴 수 있다. 
# 즉, 종(Species)별 꽃받침 폭(Sepal.Width)의 평균값들 중에서
# 적어도 어느 하나의 종은 통계적으로 유의한 차이가 있는 값을 가진다고 말 할 수 있다. 



# 사후검정 수행 (R의 TukeyHSD함수를 이용)
# 세 가지 종들 중 특히나 어떠한 종들 간에 꽃받침의 폭에 차이가 있는지를 파악하기 위해 사후검정을 수행
TukeyHSD(aov(Sepal.Width~Species, data=iris))
# 예제의 사후분석 결과를 보면 versicolor-setosa, virginica-setosa, virginica-versicolor의
# 세 가지 비교에 대한 모든 (수정된) p-value값(p adj)이 0.05보다 작으므로 각각의 비교에 대한 귀무가설을 모두 기각한다. 
# 즉 모든 종들에 대해서 꽃받침 폭의 평균값은 각각 통계적으로 유의한 차이가 있다는 것을 알 수 있다.

# 또한 diff는 하이픈(-)의 왼쪽 집단과 오른쪽 집단 간 반응값의 차이를 나타내는데, 
# versicolor-setosa 에 대한 diff값은 음수이므로, 꽃받침의 폭은 종이 versicolor일 때보다  
# setosa일 때가 통계적으로 유의하게 큰 값을 가진다고 해석할 수 있다.

install.packages("doBy")
library(doBy)
install.packages("agricolae")
library(agricolae)

comparison <- scheffe.test(result, # ANOVA model 
                           "Species", # vector treatment applied to each experimental unit
                           alpha = 0.05, # significant level
                           console=TRUE, # print out
                           )
# 마지막 결과에서 setosa, vitginica, versicolor 각각 다른 그룹으로 말하고 있음.


#ex) 정유사에서 온도(Factor, one-way)에 따라서 휘발유 생산량에 변화가 있는지 (즉, 영향이 있는지) 알아보기 위하여 
#    온도를 3가지 조건(3 Factor Levels)으로 실험설계를 하여 10번에 걸쳐서 휘발유 생산량을 측정하였습니다. 
#    관찰값이 아래와 같을 때 조사되었을 때 온도의 조건에 따라서 휘발유 생산량에 차이가 있는지 
#    유의수준 α = 0.1 로 검정하시오.

# 온도 조건 1 - {50.5, 52.1, 51.9, 52.4, 50.6, 51.4, 51.2, 52.2, 51.5, 50.8}
# 온도 조건 2 - {47.5, 47.7, 46.6, 47.1, 47.2, 47.8, 45.2, 47.4, 45.0, 47.9}
# 온도 조건 3 - {46.0, 47.1, 45.6, 47.1, 47.2, 46.4, 45.9, 47.1, 44.9, 46.2}


# Q-1. 귀무가설과 대립가설을 쓰시오.

#solution

#귀무가설 :  온도(Factor, one-way)에 따라서 휘발유 생산량에 변화가 없다.
#대립가설 :  온도(Factor, one-way)에 따라서 휘발유 생산량에 변화가 있다.
#            적어도 한 집단의 평균은 다르다.


# Q-2. 온도의 조건에 따라서 휘발유 생산량에 차이가 있는지에 대해 가설검정하시오.
#      그리고 대립가설이 채택 될 시, 사후검정을 실시하시오.
#      (정규성, 등분산성 검정은 생략하고 유의수준 0.05에서 검정하시오.)
#solution

y1 <-  c(50.5, 52.1, 51.9, 52.4, 50.6, 51.4, 51.2, 52.2, 51.5, 50.8)
y2 <-  c(47.5, 47.7, 46.6, 47.1, 47.2, 47.8, 45.2, 47.4, 45.0, 47.9)
y3 <-  c(46.0, 47.1, 45.6, 47.1, 47.2, 46.4, 45.9, 47.1, 44.9, 46.2)

y<-  c(y1,y2,y3)
group<- c(rep(1,10),rep(2,10),rep(3,10))

group_df<-data.frame(y,group)
group_df

#group 변수 factor로 변환
group_df <- transform(group_df, group = factor(group))
sapply(group_df, class)


result<- aov(y ~ group, data = group_df)

summary(result)

TukeyHSD(result)

comparison <- scheffe.test(result, # ANOVA model 
                           "group", # vector treatment applied to each experimental unit
                           alpha = 0.05, # significant level
                           console=TRUE, # print out
)





##### 6. 상관분석
#---------------------------------------------------------------------------
# 상관분석(Correlation Analysis)

## 개념
# - 상관분석 : 두 확률변수 사이의 관련성을 파악하는 방법
# - 상관계수 : 두 변수 간 관련성의 정도
# - 피어슨 상관계수 : 두 변수 간의 선형적 상관관계를 나타내며 -1~+1 사이의 값을 가짐
#   피어슨 상관계수가 양수일 때는 한 변수가 커지면 다른 변수도 선형적으로 증가함을 뜻하고, 
#   음수일 때는 한 변수가 커지면 다른 변수는 선형적으로 감소함을 의미함


## 함수
# 1) 상관계수 산출
# correlation
# cor(x, method=c("pearson", "kendall", "spearman")) # kendall 잘 안써요!

# 2) 상관계수에 대한 검정
# - cor.test(x, y, method=c("pearson", "kendal", "spearman"))
#   x, y : 상관계수에 대한 검정을 수행할 숫자형 벡터
#   alternative : 대립가설 (기본값은 양측 검정)
#   method : 상관계수의 종류 (기본값은 피어슨)
#--------------------------------------------------------------------------

# 예제 : c(1,2,3,4,5)와 c(1,0,3,4,5) 간의 피어슨 상관계수를 산출하고, 
# 그것에 대한 검정을 수행해보자.
x<-c(1,2,3,4,5)
y<-c(1,0,3,4,5)

cor(c(1,2,3,4,5), c(1,0,3,4,5))   #피어슨 상관계수 산출
cor.test(c(1,2,3,4,5), c(1,0,3,4,5), method="pearson")    #피어슨 상관계수 검정

# 상관계수에 대한 검정을 수행한 결과, p-value가 0.02937로 0.05보다 작으므로
# 통계적으로 유의하다고 판단할 수 있다.
# 상관계수는 0.9149914 로 양수이며 그 절댓값이 1에 가까운 큰 숫자이다.
# 따라서 두 숫자형 벡터 간에는 아주 강한 양의 상관관계가 존재한다고 볼 수 있다.

# 예제 : 두 명의 의사가 환자 15명을 대상으로 통증 정도를 0점(없음)에서 10점(매우 심함)까지 점수화 하였다.
#        두 의사의 통증 점수에 대한 상관관계분석을 실시하라.

A_doc<-c(4,6,3,4,8,5,8,7,9,4,8,4,3,6,7)
B_doc<-c(5,5,3,4,8,7,2,6,9,5,6,4,3,7,7)

cor(A_doc, B_doc)
# cor.test(A_doc, B_doc)
# cor.test(A_doc, B_doc, method="pearson")
cor.test(A_doc, B_doc, method="spearman") # 

#warning의 경우, 같은 값들이 존재하여 나타나는 경고임.
# 상관계수에 대한 검정을 수행한 결과, p-value가  0.01638  로 0.05보다 작으므로
# 통계적으로 상관관계가 있다 라고 판단할 수 있다.
# 상관계수는 0.607152 로 그 절댓값이  1 에 가까운 큰 숫자이다.
# 따라서 두 벡터 간에는  강한 양의 상관관계가 있다.
# rm(list=ls())
##### 7. 회귀분석
#---------------------------------------------------------------------------

# 7.1 회귀분석

## 개념
# - 하나나 그 이상의 독립변수들이 종속변수에 미치는 영향을 추정할 수 있는 통계기법
# - 독립변수의 개수가 하나       : 단순선형회귀분석, 
# - 독립변수의 개수가 두 개 이상 : 다중선형회귀분석


## 함수
# lm(formula, data)
# formula : 종속변수(반응변수)~독립변수(설명변수), 독립변수가 여러개일 때는 +로 연결
# data : 회귀분석을 수행할 데이터명

#---------------------------------------------------------------------------

# 단순, 다중 회귀분석 예

set.seed(2)                           
x <- runif(10, 0, 11)             
y <- runif(10, 11, 20)                 
dfrm <- data.frame(x, y)
dfrm
plot(y~x)
m<-lm(y ~ x, data=dfrm)                   
# y = 15.82328 - 0.09608 * x
summary(m)

set.seed(2)                             
y <- runif(10, -10, 20)               
u <- runif(10, 0, 11)                
v <- runif(10, 11, 20)              
w <- runif(10, 1, 30)                 
dfrm <- data.frame(y, u, v, w)
dfrm
m <- lm(y ~ u + v + w)    
m
#  y = 3.8503 - 0.2090 * u + 0.4120 * v - 0.1609 * w

summary(m)

# F통계량 : 0.1029
# p-value : 0.9554 (유의수준 5%하에 유의하지 않음 0.05)
# 회귀계수 : u,v,w 모두 p-value가 0.05 보다 커서 회귀계수의 추정들이 통계적으로 유의하지 않음
# 결정계수 R-squared = 0.04894, Adjusted R-squared = -0.4266 : 회귀식이 데이터를 적절하게 설명하지 못함

data(ChickWeight, package="datasets")   
head(ChickWeight)

Chick <- ChickWeight[ChickWeight$Diet == 1, ]  
Chick
Chick <- ChickWeight[ChickWeight$Chick == 1, ]  
Chick

m <- lm(weight~Time, data=Chick)
m
#  weight = 24.465 + 7.988 * time 
summary(m)

plot(Chick$weight~Chick$Time)
abline(m$coef, lty="dotted")


# F통계량 : 232.9
# p-value : 0.0000002974 (유의수준 5%하에 회귀모형이 통계적으로 유의함)
# 회귀계수 : time 의 p-value가 0.05 보다 작아서 회귀계수의 추정이 통계적으로 유의함
# 결정계수 R-squared = 0.9588, Adjusted R-squared = 0.9547 : 회귀식이 데이터를 적절하게 설명함


# 예제 : MASS 패키지의“Cars93”라는 데이터셋의 가격(Price)을 종속변수로 선정하고 엔진크기 (EngineSize), 
# RPM, 무게(Weight)를 이용해서 다중회귀분석을 실시해보자.

# 패키지 및 데이터 불러오기
library(MASS)
head(Cars93)


# 다중회귀분석 수행
lm(Price~EngineSize+RPM+Weight, data=Cars93) 
summary(lm(Price~EngineSize+RPM+Weight, data=Cars93))

# F-통계량은 37.98이며 유의확률 p-value 값이 6.746e-16로 유의수준 0.05 하에서 
# 추정된 회귀 모형이 통계적으로 매우 유의함을 알 수 있다. 
# 결정계수와 수정된 결정계수는 0.5614으로 조금 낮게 나타났고, 이는 해당 회귀식이
# 전체 데이터에 대해 약 56% 만큼의 변동을 설명할 수 있다는 의미이다. 
# 따라서 이 회귀식이 데이터를 적절하게 설명하고 있다고는 할 수 없다. 

# 회귀계수들의 p-값들도 0.05보다 작으므로 회귀계수의 추정치들이 통계적으로 유의하다. 
# 결정계수가 낮아 데이터의 설명력은 낮지만 회귀분석결과에서 회귀식과 회귀계수들이 
# 통계적으로 유의하여 자동차의 가격을 엔진의 크기와 RPM 그리고 무게로 추정할 수 있다.



#---------------------------------------------------------------------------------------------

# 7.2 최적 회귀방정식의 선택

## 개념

# 모형선택(exploratory analysis) : 분석 데이터에 가장 잘 맞는 모형을 찾아내는 방법

# - 설명변수 선택 : 필요한 변수만 상황에 따라 타협을 통해 선택

# - 모든 가능한 조합의 회귀분석(All possible regression) : 모든 가능한 독립변수들의 조합에 대한 
#   회귀모형을 분석해 가장 적합한 회귀모형을 선택


# - 벌점화된 선택기준 : 모형의 복잡도에 벌점을 주는 방법으로 AIC 방법과, BIC 방법이 주로 사용된다.
#   모든 후보 모형들에 대해 AIC 또는 BIC를 계산하고 그 중 최소가 되는 모형을 선택한다.


# - 변수선택법(Variable Selection) 
# 1) 전진선택법(forward selection) : 절편만 있는 상수모형으로부터 시작해 
#    중요하다고 생각되는 설명변수부터 차례로 모형에 추가시킨다.
# 2) 후진제거법(backward elimination) : 모든 독립변수를 포함한 모형에서 출발해 가장 적은 
#    영향을 주는 변수부터 하나씩 제거하면서 더 이상 제거할 변수가 없을 때의 모 형을 선택한다. 
# 3) 단계별방법(stepwise method) : 전진선택법에 의해 변수를 추가하면서 새롭게 추가된 변수에 기인해 
#    기존 변수가 그 중요도가 약화되면 해당변수를 제거하는 등 단계별로 추가 또는 제거되는 변수의 
#    여부를 검토해 더 이상 모형에 변화가 없을 때 중단한다.

#---------------------------------------------------------------------------------------------

## 변수선택을 위한 함수
# step(object, scope=list(lower=~1, upper=~입력변수),  direction=("both", "forward", "backward"))
# scope : 변수선택 과정에서 설정할 수 있는 가장 큰 모형(upper) 혹은 가장 작은 모형(lower)의 포뮬러를 지정
# (scope 지정하지 않을 시, 전진선택법에서는 현재 선택한 모형을 가장 큰 모형으로, 
# 후진제거법에서는 상수항만 있는 모형을 가장 작은 모형으로 설정한다.)

# direction : 변수선택법(forward : 전진선택법, backward : 후진제거법, both : 단계적선택법)

#---------------------------------------------------------------------------------------------

# 예제 : x1, x2, x3, x4를 독립변수로 가지고 y를 종속변수로 가지는 선형회귀모형을 생성한 뒤, 
#        step()함수를 활용하여 전진선택법으로 변수를 선택해보자.


# 데이터프레임 생성
x1 <- c(7, 1, 11, 11, 7, 11, 3, 1, 2,21, 1,11, 10)
x2 <- c(26, 29, 56, 31, 52, 55, 71,31, 54, 47, 40, 66, 68)
x3 <- c(6, 15, 8, 8, 6, 9, 17, 22, 18, 4, 23, 9, 8)
x4 <- c(60, 52, 20, 47, 33, 22, 6, 44, 22, 26, 34, 12, 12)
y <- c(78.5, 74.3, 104.3, 87.6, 95.9, 109.2, 102.7, 72.5, 93.1, 115.9, 83.8, 113.3, 109.4)
df <- data.frame(x1, x2, x3, x4, y)
head(df)


# 전진선택법 적용
step(lm(y~1, data=df), scope=list(lower=~1, upper=~x1+x2+x3+x4), direction="forward")

# 전진선택법을 실시한 결과, 가장 먼저 선택된 변수는 AIC값이 58.852으로 가장 낮은 x4였다. 
# x4에 x1을 추가하였을 때 AIC 값이 28.742로 낮아지게 되었고, 
# x2를 추가하였을 때 AIC 값이 24.974으로 최소화되어 더 이상 AIC를 낮출 수 없어 변수선택을 종료하게 되었다.
# 최종적으로 선택된 추정된 회귀식은 y = 71.6483 -0.2365*x4 + 1.4519*x1 + 0.4161*x2 이다.


# 선택된 변수를 이용한 회귀방정식 생성 및 통계적 유의성 검정
lm_df<-lm(y ~ x4 + x1 + x2, data = df)
summary(lm_df)

# 회귀분석 결과, 모든 회귀계수들의 p-value값이 0.05보다 작으므로 회귀계수의 추정치들이 통계적으로 유의하다. 
# 수정된 결정계수는 0.9764로 해당 회귀식은 전체 데이터의 변동 중 약 97%를 설명할 수 있다.
# 회귀모형에 대한 p-value 값이 3.323e-08 이므로 추정된 회귀식은 유의수준 0.05 하에서 통계적으로 매우 유의하다.


# 후진제거법 적용
# 예) 스위스의 프랑스어 사용지역의 출산율(Fertility)에 영향을 끼치는 변수들을 찾기위해
#     후진제거법을 이용하여 회귀모형을 도출한다.

data(swiss)

str(swiss)   #출산율(Fertility)을 포함하여 총 6개의 변수가 존재

lm.model<-lm(Fertility~., dat=swiss)

back.model<-step(lm.model, Fertility~1, direction="backward")

# 전진선택법을 실시한 결과, 가장 먼저 제거된 변수의 AIC값이 189.86으로 가장 낮은 Exmination이다. 
# Exmination을 제거하였을 때 AIC 값이 189.86으로 최소화되어 더 이상 AIC를 낮출 수 없어 변수선택을 종료하게 되었다.

summary(back.model)

# 최종적으로 선택된 추정된 회귀식은 아래와 같다.
# Fertility = 62.10131 -0.15462*Agriculture -0.98026*Education + 0.12467*Cathiolic +1.07844*Infant.Mortality

#---------------------------------------------------------------------------------------------

# 7.3 로지스틱 회귀분석

## 개념

# 로지스틱 회귀분석 : 반응변수가 범주형인 경우 적용되는 회귀분석
##                         새로운 설명변수가 주어질 때 반응변수의 각 범주에 속할 확률이 얼마인지를 추정하여
##                         추정확률을 기준치에 따라 분류하는 목적으로 활용

# glm(formula,
#     data,
#     family,      #"binomial","gaussian","Gamma","poisson" 등이 있음
#     ...)

#최적 회귀방정식의 선택
# step(scope,        #변수선택 과정에서 설정할 수 있는 가장 큰 모형 혹은 가장 작은 모형을 설정
#                    #전진선택법에서는 가장 큰모형으로, 후진제거법에서는 가장 작은 모형으로 설정
#      direction,    #변수 선택법(forward, backward, stepwise)
#      ...)

#---------------------------------------------------------------------------------------------

# 예) turnout 데이터는 1992년 미국 총선에 대한 데이터로써, 
# race(인종), 연령(age), 교육수준(educate), income(수입)에 따른 vote(투표여부)를 파악할 수 있다. 
# 이 데이터는 투표를 했느냐 안 했느냐하는 종속변수에 관심이 있어 로지스틱 회귀분석을 실시했다.
install.packages("Zelig")
library(Zelig)

data("turnout")
str(turnout)

logi<-glm(vote~., family=binomial, data=turnout)
summary(logi)
# 종속변수는 vote이며, 독립변수는 race, age, educate, income이다.
# 해당 모델에서 유의수준 0.05 하에서 race::white를 제외한 변수는 유의하게 나타남.
# 로지스틱 회귀모형의 적합도를 검정하기 위해서는 호스머-램쇼 검정을 실시해야함.
